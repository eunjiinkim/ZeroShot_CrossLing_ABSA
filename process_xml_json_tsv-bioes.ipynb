{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e9b53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import json\n",
    "from glob import glob\n",
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c891a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You need to download dataset\n",
    "## Check https://alt.qcri.org/semeval2016/task5/index.php?id=data-and-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5179ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filenames = glob('raw_dataset/*.xml')\n",
    "\n",
    "# for fname in filenames:\n",
    "#     o = xmltodict.parse(open(fname, 'rt').read())\n",
    "#     fn = fname.split('/')[-1].split('.')[0]\n",
    "#     save_name = os.path.join('raw_dataset', f\"{fn}.json\")\n",
    "#     print(save_name)\n",
    "#     with open(save_name, 'wt') as f:\n",
    "#         json.dump(o, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4755f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonfilenames = glob('raw_dataset/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a44382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def remove_null(line):\n",
    "#     res=[]\n",
    "#     line=line.split(',')\n",
    "#     for l in line:\n",
    "#         if not 'NULL' in l:\n",
    "#             res.append(l)\n",
    "#     return ' , '.join(res)\n",
    "\n",
    "# def sub_null(line):\n",
    "#     res=[]\n",
    "#     line=line.split(',')\n",
    "#     for l in line:\n",
    "#         if not 'NULL' in l:\n",
    "#             res.append(l)\n",
    "#         else:\n",
    "#             l = l.replace('NULL', '')\n",
    "#             l = l.replace('  ', ' ')\n",
    "#             res.append(l)\n",
    "#     return ' , '.join(res)\n",
    "\n",
    "\n",
    "\n",
    "def remove_null(line):\n",
    "    res=[]\n",
    "    line=line.split(\"<&>\") # \",\"\n",
    "    for l in line:\n",
    "        if not 'NULL' in l:\n",
    "            res.append(l.strip())\n",
    "    return ' <&> '.join(res)\n",
    "\n",
    "# def sub_null(line):\n",
    "# #     res=[]\n",
    "# #     line=line.split(',')\n",
    "# #     for l in line:\n",
    "# #         l = l.replace('NULL', 'None')\n",
    "# #         l = l.replace('  ', ' ')\n",
    "# #         res.append(l)\n",
    "    \n",
    "#     return line.replace('NULL','None')\n",
    "\n",
    "def rm_dup(line):\n",
    "#     line = line.\n",
    "    return ' <&> '.join(list(dict.fromkeys(line.split(' <&> '))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d471ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2tsv(filename):\n",
    "    with open(filename,'r') as f:\n",
    "        data=json.load(f)\n",
    "\n",
    "    f.close()\n",
    "    sentences = []\n",
    "    polarity = []\n",
    "    term = []\n",
    "    labels = []\n",
    "    category = []\n",
    "    labels2 = []\n",
    "    bio_labels = []\n",
    "    for d in data['Reviews']['Review']:\n",
    "        infos = d['sentences']['sentence']\n",
    "        if type(infos) == dict:\n",
    "            infos = [infos]\n",
    "        for review in infos:\n",
    "            tmp_pol = []\n",
    "            tmp_term = []\n",
    "            tmp_cat = []\n",
    "#             print(review)\n",
    "            if 'Opinions' not in review:\n",
    "                continue\n",
    "            if review['Opinions']:\n",
    "                sentences.append(review['text'])\n",
    "                opinion = review['Opinions']['Opinion']\n",
    "                if type(opinion) == dict:\n",
    "                    tmp_pol.append(opinion['@polarity'])\n",
    "                    tmp_term.append(opinion['@target'])\n",
    "                    tmp_cat.append(opinion['@category'])\n",
    "                    \n",
    "                    lb = opinion['@target'] + ' ' + opinion['@polarity']\n",
    "                    lb2 = opinion['@category'].split('#')[0].lower() + ' ' + opinion['@target'] + ' ' + opinion['@polarity']\n",
    "                    s, e = int(opinion['@from']) , int(opinion['@to'])\n",
    "#                     if review['text'] == 'Servicio esmerado.':\n",
    "#                         print(s, e)\n",
    "                    lb_bio=['O' for _ in range(len(review['text'].split(' ')))]\n",
    "                    if opinion['@target'] != 'NULL':\n",
    "\n",
    "                        if (s and e) or (s==0):\n",
    "                            tmp_bio=review['text'].replace(review['text'][s:e], '<TERM>'+review['text'][s:e]+'<TERM>')\n",
    "                            lst=[i for i, word in enumerate(tmp_bio.split()) if '<TERM>' in word]\n",
    "                            if len(lst)==1:\n",
    "                                lb_bio[lst[0]] = 'S-{}'.format(opinion['@polarity'])\n",
    "                            else:\n",
    "                                lst = [i for i in range(lst[0],lst[1]+1)]\n",
    "                                lb_bio[lst[0]] = 'B-{}'.format(opinion['@polarity'])\n",
    "\n",
    "                                for idx in lst[1:-1]:\n",
    "                                        lb_bio[idx] = 'I-{}'.format(opinion['@polarity'])\n",
    "                                lb_bio[lst[-1]] = 'E-{}'.format(opinion['@polarity'])\n",
    "\n",
    "                else:\n",
    "                    lb = ''\n",
    "                    lb2 = ''\n",
    "                    lb_bio = ['O' for _ in range(len(review['text'].split(' ')))]\n",
    "                    for opinion in review['Opinions']['Opinion']:\n",
    "        #             print(opinion)\n",
    "                        tmp_pol.append(opinion['@polarity'])\n",
    "                        tmp_term.append(opinion['@target'])\n",
    "                        tmp_cat.append(opinion['@category'])\n",
    "                    \n",
    "                        l = opinion['@target'] + ' ' + opinion['@polarity']\n",
    "                        l2 = opinion['@category'].split('#')[0].lower() + ' ' + opinion['@target'] + ' ' + opinion['@polarity']\n",
    "\n",
    "\n",
    "                        lb += l\n",
    "                        lb += ' <&> '\n",
    "\n",
    "                        lb2 += l2\n",
    "                        lb2 += ' <&> '\n",
    "                    \n",
    "                        s, e = int(opinion['@from']) , int(opinion['@to'])\n",
    "                        if opinion['@target'] != 'NULL':\n",
    "                            if (s and e) or (s==0):\n",
    "                                tmp_bio=review['text'].replace(review['text'][s:e], '<TERM>'+review['text'][s:e]+'<TERM>')\n",
    "                                lst=[i for i, word in enumerate(tmp_bio.split()) if '<TERM>' in word]\n",
    "                                if len(lst)==1:\n",
    "                                    lb_bio[lst[0]] = 'S-{}'.format(opinion['@polarity'])\n",
    "                                else:\n",
    "                                    lst = [i for i in range(lst[0],lst[1]+1)]\n",
    "                                    lb_bio[lst[0]] = 'B-{}'.format(opinion['@polarity'])\n",
    "\n",
    "                                    for idx in lst[1:-1]:\n",
    "                                            lb_bio[idx] = 'I-{}'.format(opinion['@polarity'])\n",
    "\n",
    "                                    lb_bio[lst[-1]] = 'E-{}'.format(opinion['@polarity'])\n",
    "                if lb.strip()[-3:] == '<&>':\n",
    "                    lb = lb[:-4]\n",
    "                else:\n",
    "                    lb = lb.strip()\n",
    "                if lb2.strip()[-3:] == '<&>':\n",
    "                    lb2 = lb2[:-4]\n",
    "                else:\n",
    "                    lb2 = lb2.strip()\n",
    "                polarity.append(' <&> '.join(tmp_pol))\n",
    "                term.append(' <&> '.join(tmp_term))\n",
    "                labels.append(lb)\n",
    "                labels2.append(lb2)\n",
    "                \n",
    "                \n",
    "                    \n",
    "                category.append(' , '.join(tmp_cat))\n",
    "                bio_labels.append(' '.join(lb_bio))\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    df['review'] = sentences\n",
    "    df['labels'] = labels\n",
    "    df['labels'] = df['labels'].map(lambda x: rm_dup(x))\n",
    "    df['category'] = category\n",
    "#     df['labels_acsd'] = labels2\n",
    "    \n",
    "    df['labels_bieos'] = bio_labels\n",
    "\n",
    "    df['labels_rm'] = df['labels'].map(lambda x: remove_null(x))\n",
    "    df['labels_rm'] = df['labels_rm'].map(lambda x: rm_dup(x))\n",
    "    \n",
    "#     df['labels_acsd_rm'] = df['labels_acsd'].map(lambda x: remove_null(x))\n",
    "\n",
    "\n",
    "#     df['labels_sub'] = df['labels'].map(lambda x: sub_null(x))\n",
    "#     df['labels_acsd_sub'] = df['labels_acsd'].map(lambda x: sub_null(x))     \n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(len(df)):\n",
    "        tmp=df['review'][i].split(' ')\n",
    "        tmp_lb = df['labels_bieos'][i].split(' ')\n",
    "        res = []\n",
    "        res_lb = []\n",
    "        for t, b in zip(tmp, tmp_lb):\n",
    "            if t != '':\n",
    "                res.append(t)\n",
    "                res_lb.append(b)\n",
    "        assert len(res) == len(res_lb)\n",
    "        df['review'][i] = ' '.join(res)\n",
    "        df['labels_bieos'][i] = ' '.join(res_lb)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    lang, dt = filename.split('/')[1].split('_')[2], filename.split('/')[1].split('_')[-1].split('.json')[0]\n",
    "    \n",
    "    if lang=='du': lang = 'nl'\n",
    "    new_name =  'datasets/res16_' + lang + '_' + dt + '_bieos.tsv'\n",
    "    df.to_csv(new_name, index=False, sep='\\t')\n",
    "#     return df\n",
    "    print('>> from {} to {}'.format(filename, new_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46703aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> from raw_dataset/ABSA16_res_en_train.json to datasets/res16_en_train_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_du_train.json to datasets/res16_nl_train_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_fr_test.json to datasets/res16_fr_test_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_es_test.json to datasets/res16_es_test_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_ru_train.json to datasets/res16_ru_train_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_tu_train.json to datasets/res16_tu_train_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_en_test.json to datasets/res16_en_test_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_fr_train.json to datasets/res16_fr_train_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_ru_test.json to datasets/res16_ru_test_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_tu_test.json to datasets/res16_tu_test_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_du_test.json to datasets/res16_nl_test_bieos.tsv\n",
      ">> from raw_dataset/ABSA16_res_es_train.json to datasets/res16_es_train_bieos.tsv\n"
     ]
    }
   ],
   "source": [
    "for fn in jsonfilenames:\n",
    "    json2tsv(fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
